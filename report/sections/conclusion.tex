\section{Conclusion}

In this project, we successfully implemented a lightweight deep learning framework from scratch in C++ with CUDA support, modeled after PyTorchâ€™s nn.Module API. The core focus was on modularity and device-agnostic design, enabling seamless execution on both CPU and GPU.

We tested the framework by training a simple neural network on the MNIST dataset. The training process demonstrated convergence of the loss over epochs, validating both the correctness of our CUDA kernels and the integrity of the backpropagation pipeline. Additionally, the framework's object-oriented design allows for easy integration of new layers and training routines, making it suitable for future extensions.

This project reinforced foundational concepts in deep learning, CUDA programming, and software design for neural network frameworks. It lays the groundwork for building more complex models and training routines, and opens avenues for performance optimization and support for additional CUDA operations.